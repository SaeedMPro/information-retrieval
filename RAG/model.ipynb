{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.10.0)\n",
      "Requirement already satisfied: openai in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.65.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio<5,>=3.5.0->openai) (3.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saeedm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\SaeedM\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers pandas faiss-cpu openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration:\n",
      "{\n",
      "  \"embedding_model\": \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
      "  \"lm_studio\": {\n",
      "    \"base_url\": \"http://192.168.220.1:3000/v1/\",\n",
      "    \"api_key\": \"lm-studio\"\n",
      "  },\n",
      "  \"model_identifier\": \"dorna2-llama3.1-8b-instruct\",\n",
      "  \"top_k\": 5,\n",
      "  \"system_template\": \"شما یک دستیار هوشمند فارسی هستید. با استفاده از اطلاعات داده شده به سوالات کاربر پاسخ دقیق و مفصل بدهید.\",\n",
      "  \"retrieval_method\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(json.dumps(config, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding & Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfebc4a1ece4e8ab0b5965fe287d21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created with 1085 documents\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv(\"university_info.csv\")\n",
    "df.fillna(\"\", inplace=True)\n",
    "\n",
    "def create_document(row):\n",
    "    return (\n",
    "        f\"نام و نام خانوادگی: {row['نام و نام خانوادگی']}. \"\n",
    "        f\"عنوان سازمانی: {row['عنوان سازمانی']}. \"\n",
    "        f\"واحد سازمانی: {row['واحد سازمانی']}. \"\n",
    "        f\"شماره داخلی: {row['شماره داخلی']}. \"\n",
    "        f\"شماره مستقیم: {row['شماره مستقیم']}. \"\n",
    "        f\"ایمیل: {row['ایمیل']}.\"\n",
    "    )\n",
    "\n",
    "csv_documents = df.apply(create_document, axis=1).tolist()\n",
    "\n",
    "with open(\"info.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_content = f.read()\n",
    "txt_paragraphs = [p.strip() for p in text_content.split(\"\\n\\n\") if p.strip() != \"\"]\n",
    "\n",
    "all_documents = csv_documents + txt_paragraphs\n",
    "\n",
    "#  Embedding Generation\n",
    "embed_model = SentenceTransformer(config['embedding_model'])\n",
    "embeddings = embed_model.encode(all_documents, show_progress_bar=True)\n",
    "\n",
    "#  Indexing\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "# Save index and documents\n",
    "faiss.write_index(index, \"vector_index.faiss\")\n",
    "with open(\"documents.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_documents, f)\n",
    "\n",
    "print(f\"Index created with {len(all_documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersianRetriever:\n",
    "    def __init__(self, index_path, documents_path):\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        with open(documents_path, \"rb\") as f:\n",
    "            self.documents = pickle.load(f)\n",
    "        self.embed_model = SentenceTransformer(config['embedding_model'])\n",
    "    \n",
    "    def get_relevant_documents(self, query, top_k=config[\"top_k\"]):\n",
    "        query_embed = self.embed_model.encode(query)\n",
    "        distances, indices = self.index.search(np.array([query_embed], dtype=np.float32), top_k)\n",
    "        print(\"distances from query :\", distances)\n",
    "        return [self.documents[i] for i in indices[0] if i < len(self.documents)]\n",
    "\n",
    "retriever = PersianRetriever(\n",
    "    index_path=\"vector_index.faiss\",\n",
    "    documents_path=\"documents.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM Studio Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=config['lm_studio']['base_url'],\n",
    "    api_key=config['lm_studio']['api_key']\n",
    ")\n",
    "\n",
    "class PersianLLM:\n",
    "    def __init__(self, model_identifier, system_template=config['system_template']):\n",
    "        self.model = model_identifier\n",
    "        self.system_template = system_template\n",
    "    \n",
    "    def generate(self, context, user_query, temperature=0.7):\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_template},\n",
    "                    {\"role\": \"user\", \"content\": f\"متن زمینه:\\n{context}\\n\\nسوال: {user_query}\"}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return \"Error in generate function!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Transformation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_query_generation(user_query, llm=None):\n",
    "    variations = [\n",
    "        f\"{user_query}\",\n",
    "        f\"لطفاً توضیح دهید: {user_query}\",\n",
    "        f\"مفهوم اصلی {user_query} چیست؟\",\n",
    "        f\"ارائه مثال برای {user_query}\",\n",
    "        f\"خلاصه‌ای درباره {user_query}\"\n",
    "    ]\n",
    "    \n",
    "    if llm:\n",
    "        prompt = f\"سه روش مختلف برای پرسش درباره این موضوع ایجاد کن: {user_query}\"\n",
    "        llm_variations = llm.invoke(prompt).split('\\n')[:3]\n",
    "        variations.extend(llm_variations)\n",
    "    \n",
    "    return variations\n",
    "\n",
    "def multi_query_retrieval(retriever, user_query, llm=None, top_k=5):\n",
    "    queries = multi_query_generation(user_query, llm)\n",
    "    results = []\n",
    "    for query in queries:\n",
    "        results.extend(retriever.get_relevant_documents(query, top_k=top_k))\n",
    "    return list(set(results))[:top_k]\n",
    "\n",
    "def rag_fusion(retriever, queries, top_k=5):\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    doc_scores = defaultdict(float)\n",
    "    for query in queries:\n",
    "        docs = retriever.get_relevant_documents(query, top_k=top_k)\n",
    "        for i, doc in enumerate(docs):\n",
    "            # Use reciprocal rank fusion\n",
    "            doc_scores[doc] += 1/(i + 1)\n",
    "    \n",
    "    sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, score in sorted_docs[:top_k]]\n",
    "\n",
    "def step_back_retrieval(retriever, user_query, top_k=5):\n",
    "    initial_results = retriever.get_relevant_documents(user_query, top_k=top_k)\n",
    "    if not initial_results:\n",
    "        return retriever.get_relevant_documents(f\"موضوع کلی: {user_query}\", top_k=top_k)\n",
    "    return initial_results\n",
    "\n",
    "def hyde_retrieval(retriever, user_query, llm, top_k=5):\n",
    "    synthetic_answer = llm.invoke(f\"فرض کنید متخصص هستید، خلاصه‌ای درباره {user_query} ارائه دهید.\")\n",
    "    return retriever.get_relevant_documents(synthetic_answer, top_k=top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answer(user_query, retriever, llm, method=\"default\", top_k=config[\"top_k\"]):\n",
    "    method = config['retrieval_method']\n",
    "    if method == \"multi_query\":\n",
    "        return multi_query_retrieval(retriever, user_query, llm, top_k)\n",
    "    elif method == \"rag_fusion\":\n",
    "        queries = multi_query_generation(user_query, llm, top_k)\n",
    "        return rag_fusion(retriever, queries)\n",
    "    elif method == \"step_back\":\n",
    "        return step_back_retrieval(retriever, user_query, top_k)\n",
    "    elif method == \"hyde\":\n",
    "        return hyde_retrieval(retriever, user_query, llm, top_k)\n",
    "    else:\n",
    "        return retriever.get_relevant_documents(user_query, top_k)\n",
    "\n",
    "def format_context(documents, max_length=4000):\n",
    "    context = []\n",
    "    total_len = 0\n",
    "    for doc in documents:\n",
    "        doc_len = len(doc.split())\n",
    "        if total_len + doc_len > max_length:\n",
    "            break\n",
    "        context.append(doc)\n",
    "        total_len += doc_len\n",
    "    return \"\\n\\n\".join(context)\n",
    "\n",
    "def safe_serialize(obj):\n",
    "    if isinstance(obj, (str, int, float, bool)):\n",
    "        return obj\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return [safe_serialize(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: safe_serialize(v) for k, v in obj.items()}\n",
    "    else:\n",
    "        return str(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances from query : [[10.853364  11.7009945 12.542284  12.542995  12.601054 ]]\n",
      "شما به دنبال شماره داخلی دکتر کریمی هستید، که در متن زمینه ذکر نشده است. با این حال، می‌توانم اطلاعات تماس سایر اعضای هیأت علمی دانشکده دامپزشکی را برای شما فراهم کنم.\n",
      "آیا می‌خواهید شماره تلفن یا ایمیل سایر اعضای هیأت علمی را نیز داشته باشید؟\n",
      "distances from query : [[10.601017 10.870323 10.934126 10.952851 11.091666]]\n",
      "محمد رضائی، عضو هیأت علمی گروه الهیات و دانشکده علوم انسانی، شماره داخلی 6147 را دارد.\n",
      "distances from query : [[8.165365 8.383644 8.399237 8.581251 8.697864]]\n",
      "متاسفانه با اطلاعات داده شده نمی‌توانم به سوال شما پاسخ دهم. لطفا جزئیات بیشتری در مورد \"دکتر رضا محمدی\" ارائه دهید تا بتوانم به سوال شما پاسخ دهم. ممکن است این فرد در یکی از واحدهای سازمانی ذکر شده کار کند و شماره داخلی او را بتوان پیدا کرد.\n",
      "distances from query : [[ 9.192681  11.2084875 11.387823  11.559641  11.630263 ]]\n",
      "برای تماس با این افراد، می‌توانید از روش‌های زیر استفاده کنید:\n",
      "- برای تماس از داخل دانشگاه:\n",
      "- با ۹ در کنار شماره داخلی مورد نظر تماس بگیرید.\n",
      "- مثال: اگر بخواهید با آقای علیرضا سازمند تماس بگیرید، شماره ۹۶۱۰ را می‌گیرد.\n",
      "- برای تماس از خارج از دانشگاه:\n",
      "- ابتدا عدد ۳۱۴۰ را به ابتدای شماره داخلی اضافه کنید.\n",
      "- سپس پیش‌کد شهر همدان (۰۸۱) را نیز اضافه نمایید.\n",
      "- مثال: اگر بخواهید با آقای علیرضا سازمند تماس بگیرید، شماره ۳۱۴۰۶۰۱۰-۰۸۱ را می‌گیرد.\n",
      "لطفا توجه داشته باشید که همه خطوط داخلی دانشگاه مستقیم و بدون نیاز به اپراتور از بیرون نیز قابل دسترسی هستند.\n",
      "distances from query : [[7.0603633 7.0682907 7.12495   7.128694  7.290026 ]]\n",
      "متاسفانه با اطلاعات داده شده نمی‌توانم به سوال شما پاسخ دهم، زیرا هیچ اطلاعاتی در مورد \"رضا محمدی\" در متن زمینه ارائه نشده است. لطفاً جزئیات بیشتری در اختیار من قرار دهید تا بتوانم بهتر به سوال شما پاسخ دهم.\n",
      "distances from query : [[6.477337  6.477337  6.8722115 6.968895  7.3246765]]\n",
      "شماره داخلی رضا محمدی، عضو هیأت علمی گروه مهندسی کامپیوتر، **6380** است. این شماره در داخل سازمان معتبر است و برای تماس با او از داخل شبکه داخلی استفاده می‌شود. همچنین، شماره مستقیم او که برای تماس از خارج سازمان معتبر است، **31406380** است.\n",
      "distances from query : [[15.244092 15.274253 15.737707 15.792738 15.897371]]\n",
      "آیا می‌توانید اطلاعات تماس و ایمیل افراد را برای من مرتب کنید؟\n",
      "distances from query : [[11.234794  11.291954  11.691397  11.8499365 11.92424  ]]\n",
      "متاسفانه با اطلاعات داده شده نمی‌توانم به سوال شما پاسخ دهم. لطفاً سوال خود را واضح‌تر بپرسید یا اطلاعات بیشتری ارائه دهید تا بتوانم بهتر کمک کنم.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = PersianLLM(\n",
    "    model_identifier=config['model_identifier'],\n",
    "    system_template=config['system_template']\n",
    ")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_query = input(\"\\nسوال خود را وارد کنید (یا 'خروج' برای پایان): \").strip()\n",
    "        if user_query.lower() in ['exit', 'خروج']:\n",
    "            break\n",
    "    \n",
    "        docs = retrieve_answer(user_query, retriever, llm, method=config[\"retrieval_method\"])\n",
    "        context = format_context(docs)\n",
    "        \n",
    "        if not context:\n",
    "            print(\"No near chunk found.\")\n",
    "            continue\n",
    "        \n",
    "        answer = llm.generate(context, user_query)\n",
    "        print(answer)\n",
    "        \n",
    "        # Save results\n",
    "        output = {\n",
    "            \"query\": user_query,\n",
    "            \"retrieved_documents\": safe_serialize(docs),\n",
    "            \"generated_answer\": safe_serialize(answer)\n",
    "        }\n",
    "        \n",
    "        with open('output.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
